{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1b33ab2-f0e7-4ab5-b80c-aca200daef54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sas_token = \"sp=rcwl&st=2025-12-10T08:37:29Z&se=2025-12-10T16:52:29Z&spr=https&sv=2024-11-04&sr=c&sig=RDrU2ZSXEN1%2Fr%2FA6OSnBVYEVfM8hwUFilfAmD7knKBU%3D\"\n",
    "storage_account_name = \"adbprojektkakastorage\"\n",
    "container_name = \"raw\"\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.auth.type.{storage_account_name}.dfs.core.windows.net\", \"SAS\"\n",
    ")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.token.provider.type.{storage_account_name}.dfs.core.windows.net\",\n",
    "    \"org.apache.hadoop.fs.azurebfs.sas.FixedSASTokenProvider\"\n",
    ")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.sas.fixed.token.{storage_account_name}.dfs.core.windows.net\",\n",
    "    sas_token\n",
    ")\n",
    "\n",
    "base_path = f\"abfss://{container_name}@{storage_account_name}.dfs.core.windows.net\"\n",
    "print(f\"Skonfigurowano dostęp do: {base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f99c926c-2cc1-4dc5-bf37-f6621c0f9771",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, to_timestamp, month, dayofweek, hour, when, count, avg, round, lit, concat\n",
    "\n",
    "df_flights = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(f\"{base_path}/flights.csv\")\n",
    "\n",
    "df_airlines = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(f\"{base_path}/airlines.csv\")\n",
    "\n",
    "df_airports = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(f\"{base_path}/airports.csv\")\n",
    "\n",
    "df_weather = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .load(f\"{base_path}/jfk_weather_cleaned.csv\") \n",
    "\n",
    "print(\"Liczba wierszy w flights:\", df_flights.count())\n",
    "display(df_flights.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e8f58bd-d3b9-4ca5-8015-6c5635645340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_jfk = df_flights.filter(col(\"ORIGIN_AIRPORT\") == \"JFK\")\n",
    "\n",
    "print(\"Liczba wierszy w df_jfk:\", df_jfk.count())\n",
    "\n",
    "display(df_jfk.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f02a88f1-a686-462b-a961-bee838ae0e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sprawdzenie duplikatów \n",
    "duplicate_count = df_jfk.count() - df_jfk.dropDuplicates().count()\n",
    "print(f\"Liczba zduplikowanych wierszy: {duplicate_count}\")\n",
    "\n",
    "# Czy daty i godziny są wczytywane jako stringi lub liczby?\n",
    "df_jfk.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7aff595-8697-4f4a-b104-d71bc1b85d5e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765364800654}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lpad, concat, to_timestamp, lit, when, substring\n",
    "\n",
    "def clean_time_column(column_name):\n",
    "    padded = lpad(col(column_name).cast(\"string\"), 4, '0')\n",
    "    return when(padded == '2400', '0000').otherwise(padded)\n",
    "\n",
    "df_jfk_cleaned = df_jfk \\\n",
    "    .withColumn(\"CleanScheduled\", clean_time_column(\"SCHEDULED_DEPARTURE\")) \\\n",
    "    .withColumn(\"CleanDeparture\", clean_time_column(\"DEPARTURE_TIME\"))\n",
    "\n",
    "df_jfk_timestamps = df_jfk_cleaned.withColumn(\n",
    "    \"ScheduledTimestamp\",\n",
    "    to_timestamp(\n",
    "        concat(\n",
    "            col(\"YEAR\"), lit(\"-\"), \n",
    "            lpad(col(\"MONTH\"), 2, '0'), lit(\"-\"), \n",
    "            lpad(col(\"DAY\"), 2, '0'), lit(\" \"), \n",
    "            substring(col(\"CleanScheduled\"), 1, 2), lit(\":\"),\n",
    "            substring(col(\"CleanScheduled\"), 3, 2), lit(\":00\") \n",
    "        ),\n",
    "        \"yyyy-MM-dd HH:mm:ss\"\n",
    "    )\n",
    ").withColumn(\n",
    "    \"DeparturedTimestamp\",\n",
    "    to_timestamp(\n",
    "        concat(\n",
    "            col(\"YEAR\"), lit(\"-\"), \n",
    "            lpad(col(\"MONTH\"), 2, '0'), lit(\"-\"), \n",
    "            lpad(col(\"DAY\"), 2, '0'), lit(\" \"), \n",
    "            substring(col(\"CleanDeparture\"), 1, 2), lit(\":\"), \n",
    "            substring(col(\"CleanDeparture\"), 3, 2), lit(\":00\") \n",
    "        ),\n",
    "        \"yyyy-MM-dd HH:mm:ss\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df_jfk_timestamps = df_jfk_timestamps.drop(\"CleanScheduled\", \"CleanDeparture\")\n",
    "\n",
    "print(\"Sprawdzenie konwersji czasu (bez błędu 24:00):\")\n",
    "display(df_jfk_timestamps.select(\n",
    "    \"YEAR\", \"MONTH\", \"DAY\", \n",
    "    \"SCHEDULED_DEPARTURE\", \"ScheduledTimestamp\", \n",
    "    \"DEPARTURE_TIME\", \"DeparturedTimestamp\"\n",
    ").limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "178033e1-73f6-45b3-ba4d-630a08e8ea40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analiza wartości NULL \n",
    "# Sprawdzamy, czy braki w 'DEPARTURE_DELAY' pokrywają się z odwołanymi lotami ('CANCELLED' == 1)\n",
    "\n",
    "df_jfk_total_nulls = df_jfk_timestamps.select(\n",
    "    count(when(col(\"DEPARTURE_DELAY\").isNull(), 1)).alias(\"Total_Null_DepDelay\"),\n",
    "    count(when(col(\"ARRIVAL_DELAY\").isNull(), 1)).alias(\"Total_Null_ArrDelay\")\n",
    ")\n",
    "display(df_jfk_total_nulls)\n",
    "df_integrity = df_jfk_timestamps.groupBy(\"CANCELLED\").agg(\n",
    "    count(\"*\").alias(\"Total\"),\n",
    "    count(\"DEPARTURE_DELAY\").alias(\"NonNull_DepDelay\"),\n",
    "    count(when(col(\"DEPARTURE_DELAY\").isNull(), 1)).alias(\"Null_DepDelay\"),\n",
    "    count(\"ARRIVAL_DELAY\").alias(\"NonNull_ArrDelay\"),\n",
    "    count(when(col(\"ARRIVAL_DELAY\").isNull(), 1)).alias(\"Null_ArrDelay\")\n",
    ")\n",
    "display(df_integrity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77649fba-1ae5-4554-94e5-56aea3645bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dla wszystkich pustych wartości w DEPARTURE_DELAY lot został odwołany.\n",
    "\n",
    "Do zastanowienia: por que są jakieś nulle w arrival? Czy chcemy rozważać tylko te w departure, dlaczego dany samolot nie wyleciał?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e790b26-ff44-48f8-bff5-58f593119fda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGZfamZrX25vX251bGxzID0gZGZfamZrX3RpbWVzdGFtcHMuZmlsdGVyKGNvbCgiREVQQVJUVVJFX0RFTEFZIikuaXNOb3ROdWxsKCkpCmRpc3BsYXkoZGZfamZrX25vX251bGxzKQo=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView16b382e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView16b382e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView16b382e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView16b382e) ,min_max AS (SELECT `DEPARTURE_DELAY`,(SELECT MAX(`DEPARTURE_DELAY`) FROM q) `target_column_max`,(SELECT MIN(`DEPARTURE_DELAY`) FROM q) `target_column_min` FROM q) ,histogram_meta AS (SELECT `DEPARTURE_DELAY`,`target_column_min` `min_value`,IF(`target_column_max` = `target_column_min`,`target_column_max` + 1,`target_column_max`) `max_value`,(`target_column_max` - `target_column_min`) / 20 `step` FROM min_max) SELECT IF(ISNULL(`DEPARTURE_DELAY`),NULL,LEAST(WIDTH_BUCKET(`DEPARTURE_DELAY`,`min_value`,`max_value`,20),20)) `DEPARTURE_DELAY_BIN`,FIRST(`min_value` + ((IF(ISNULL(`DEPARTURE_DELAY`),NULL,LEAST(WIDTH_BUCKET(`DEPARTURE_DELAY`,`min_value`,`max_value`,20),20)) - 1) * `step`)) `DEPARTURE_DELAY_BIN_LOWER_BOUND`,FIRST(`step`) `DEPARTURE_DELAY_BIN_STEP`,COUNT(`DEPARTURE_DELAY`) `COUNT` FROM histogram_meta GROUP BY `DEPARTURE_DELAY_BIN`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView16b382e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "ScheduledTimestamp",
             "id": "column_9ab2152264"
            },
            "y": [
             {
              "column": "DEPARTURE_DELAY",
              "id": "column_9ab2152266"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "scatter",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "DEPARTURE_DELAY": {
             "type": "scatter",
             "yAxis": 0
            },
            "ScheduledTimestamp": {
             "type": "scatter",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "94fbc00c-a027-482f-9eee-66bb94dae0c2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.9375,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "ScheduledTimestamp",
           "type": "column"
          },
          {
           "column": "DEPARTURE_DELAY",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_jfk_no_nulls = df_jfk_timestamps.filter(col(\"DEPARTURE_DELAY\").isNotNull())\n",
    "display(df_jfk_no_nulls)\n",
    "print(f\"Liczba wierszy: {df_jfk_no_nulls.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d1a449f-1620-4437-a7a5-d774844e0179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyBTcHJhd2R6ZW5pZSBhbm9tYWxpaSB3IG9ww7PFum5pZW5pYWNoCiMgT3V0bGllcnMgc2tyYWpuaWUgbmlza2llIChucC4gLTMwIGkgbW5pZWopCm91dGxpZXJzX2xvdyA9IGRmX2pma190aW1lc3RhbXBzLmZpbHRlcigKICAgIGNvbCgiREVQQVJUVVJFX0RFTEFZIikgPCAtMzAKKS5zZWxlY3QoCiAgICAiQUlSTElORSIsICJPUklHSU5fQUlSUE9SVCIsICJTQ0hFRFVMRURfREVQQVJUVVJFIiwgIkRFUEFSVFVSRV9USU1FIiwgIkRFUEFSVFVSRV9ERUxBWSIsICJTY2hlZHVsZWRUaW1lc3RhbXAiLCJEZXBhcnR1cmVkVGltZXN0YW1wIgopCgojIE91dGxpZXJzIHNrcmFqbmllIHd5c29raWUgKG5wLiA+IDZoKQpvdXRsaWVyc19oaWdoID0gZGZfamZrX3RpbWVzdGFtcHMuZmlsdGVyKAogICAgY29sKCJERVBBUlRVUkVfREVMQVkiKSA+IDYgKiA2MAopLnNlbGVjdCgKICAgICJBSVJMSU5FIiwgIk9SSUdJTl9BSVJQT1JUIiwgIlNDSEVEVUxFRF9ERVBBUlRVUkUiLCAiREVQQVJUVVJFX1RJTUUiLCAiREVQQVJUVVJFX0RFTEFZIiwgIlNjaGVkdWxlZFRpbWVzdGFtcCIsIkRlcGFydHVyZWRUaW1lc3RhbXAiCikKCiMgUG/FgsSFY3plbmllCm91dGxpZXJzID0gb3V0bGllcnNfbG93LnVuaW9uKG91dGxpZXJzX2hpZ2gpCmRpc3BsYXkob3V0bGllcnMpCgpkaXNwbGF5KGRmX2pma190aW1lc3RhbXBzKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView3804f2b\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView3804f2b\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView3804f2b\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView3804f2b) ,min_max AS (SELECT `DEPARTURE_DELAY`,(SELECT MAX(`DEPARTURE_DELAY`) FROM q) `target_column_max`,(SELECT MIN(`DEPARTURE_DELAY`) FROM q) `target_column_min` FROM q) ,histogram_meta AS (SELECT `DEPARTURE_DELAY`,`target_column_min` `min_value`,IF(`target_column_max` = `target_column_min`,`target_column_max` + 1,`target_column_max`) `max_value`,(`target_column_max` - `target_column_min`) / 20 `step` FROM min_max) SELECT IF(ISNULL(`DEPARTURE_DELAY`),NULL,LEAST(WIDTH_BUCKET(`DEPARTURE_DELAY`,`min_value`,`max_value`,20),20)) `DEPARTURE_DELAY_BIN`,FIRST(`min_value` + ((IF(ISNULL(`DEPARTURE_DELAY`),NULL,LEAST(WIDTH_BUCKET(`DEPARTURE_DELAY`,`min_value`,`max_value`,20),20)) - 1) * `step`)) `DEPARTURE_DELAY_BIN_LOWER_BOUND`,FIRST(`step`) `DEPARTURE_DELAY_BIN_STEP`,COUNT(`DEPARTURE_DELAY`) `COUNT` FROM histogram_meta GROUP BY `DEPARTURE_DELAY_BIN`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView3804f2b\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "DEPARTURE_DELAY",
             "id": "column_9ab2152267"
            }
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "histogram",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numBins": 20,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {},
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "9216b630-dee1-40cb-b5b1-30fdf37bc10d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.96875,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "DEPARTURE_DELAY_BIN",
           "type": "column"
          }
         ],
         "selects": [
          {
           "alias": "DEPARTURE_DELAY_BIN",
           "args": [
            {
             "column": "DEPARTURE_DELAY",
             "type": "column"
            },
            {
             "number": 20,
             "type": "number"
            }
           ],
           "function": "BIN",
           "type": "function"
          },
          {
           "alias": "DEPARTURE_DELAY_BIN_LOWER_BOUND",
           "args": [
            {
             "column": "DEPARTURE_DELAY",
             "type": "column"
            },
            {
             "number": 20,
             "type": "number"
            }
           ],
           "function": "BIN_LOWER_BOUND",
           "type": "function"
          },
          {
           "alias": "DEPARTURE_DELAY_BIN_STEP",
           "args": [
            {
             "column": "DEPARTURE_DELAY",
             "type": "column"
            },
            {
             "number": 20,
             "type": "number"
            }
           ],
           "function": "BIN_STEP",
           "type": "function"
          },
          {
           "alias": "COUNT",
           "args": [
            {
             "column": "DEPARTURE_DELAY",
             "type": "column"
            }
           ],
           "function": "COUNT",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sprawdzenie anomalii w opóźnieniach\n",
    "# Outliers skrajnie niskie (np. -30 i mniej)\n",
    "outliers_low = df_jfk_timestamps.filter(\n",
    "    col(\"DEPARTURE_DELAY\") < -30\n",
    ").select(\n",
    "    \"AIRLINE\", \"ORIGIN_AIRPORT\", \"SCHEDULED_DEPARTURE\", \"DEPARTURE_TIME\", \"DEPARTURE_DELAY\", \"ScheduledTimestamp\",\"DeparturedTimestamp\"\n",
    ")\n",
    "\n",
    "# Outliers skrajnie wysokie (np. > 6h)\n",
    "outliers_high = df_jfk_timestamps.filter(\n",
    "    col(\"DEPARTURE_DELAY\") > 6 * 60\n",
    ").select(\n",
    "    \"AIRLINE\", \"ORIGIN_AIRPORT\", \"SCHEDULED_DEPARTURE\", \"DEPARTURE_TIME\", \"DEPARTURE_DELAY\", \"ScheduledTimestamp\",\"DeparturedTimestamp\"\n",
    ")\n",
    "\n",
    "# Połączenie\n",
    "outliers = outliers_low.union(outliers_high)\n",
    "display(outliers)\n",
    "\n",
    "display(df_jfk_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "827ca8cf-b35c-4fb7-9e79-081ea2253ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Statystyki opisowe dla opóźnień\n",
    "display(df_jfk_no_nulls.select(\"DEPARTURE_DELAY\", \"ARRIVAL_DELAY\", \"AIR_TIME\", \"DISTANCE\").summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b0519e9-c2e9-4129-b0dc-1210a99146cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Obliczamy granice IQR\n",
    "IQR = df_jfk_no_nulls.approxQuantile(\"DEPARTURE_DELAY\", [0.10, 0.90], 0.05)\n",
    "print(f\"Granice IQR: {IQR[0]} - {IQR[1]}\")\n",
    "lower_bound = IQR[0]\n",
    "upper_bound = IQR[1]\n",
    "\n",
    "df_jfk_no_outliers = df_jfk_no_nulls.filter(\n",
    "    (col(\"DEPARTURE_DELAY\") >= lower_bound) & \n",
    "    (col(\"DEPARTURE_DELAY\") <= upper_bound)\n",
    ")\n",
    "\n",
    "print(f\"Liczba wierszy przed: {df_jfk_no_nulls.count()}\")\n",
    "print(f\"Liczba wierszy po: {df_jfk_no_outliers.count()}\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39b38b0b-d170-4235-9692-813b44a22c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Statystyki opisowe dla opóźnień\n",
    "display(df_jfk_no_outliers.select(\"DEPARTURE_DELAY\", \"ARRIVAL_DELAY\", \"AIR_TIME\", \"DISTANCE\").summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ee9487d-9d8e-483e-9582-32c308ac07d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGZfZmVhdHVyZXMgPSBkZl9mbGlnaHRzLndpdGhDb2x1bW4oIklzV2Vla2VuZCIsIHdoZW4oY29sKCJEQVlfT0ZfV0VFSyIpLmlzaW4oWzYsIDddKSwgMSkub3RoZXJ3aXNlKDApKQoKIyBBbmFsaXphOiBDenkgdyB3ZWVrZW5keSBsYXRhIHNpxJkgZ29yemVqPwpkaXNwbGF5KGRmX2ZlYXR1cmVzLmdyb3VwQnkoIklzV2Vla2VuZCIpLmFnZyhhdmcoIkRFUEFSVFVSRV9ERUxBWSIpLmFsaWFzKCJBdmdfRGVsYXkiKSkp\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewf33600d\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewf33600d\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewf33600d\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewf33600d) SELECT `IsWeekend`,SUM(`Avg_Delay`) `column_a1e15dcf327`,`IsWeekend` FROM q GROUP BY `IsWeekend`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewf33600d\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "IsWeekend",
             "id": "column_a1e15dcf331"
            },
            "x": {
             "column": "IsWeekend",
             "id": "column_a1e15dcf326"
            },
            "y": [
             {
              "column": "Avg_Delay",
              "id": "column_a1e15dcf327",
              "transform": "AVG"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_a1e15dcf327": {
             "name": "Avg_Delay",
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "a70a6cb0-caec-409e-8881-ba61b9062b21",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 7.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "IsWeekend",
           "type": "column"
          },
          {
           "column": "IsWeekend",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "IsWeekend",
           "type": "column"
          },
          {
           "alias": "column_a1e15dcf327",
           "args": [
            {
             "column": "Avg_Delay",
             "type": "column"
            }
           ],
           "function": "AVG",
           "type": "function"
          },
          {
           "column": "IsWeekend",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_features = df_jfk_no_outliers.withColumn(\"IsWeekend\", when(col(\"DAY_OF_WEEK\").isin([6, 7]), 1).otherwise(0))\n",
    "\n",
    "# Analiza: Czy w weekendy lata się gorzej?\n",
    "display(df_features.groupBy(\"IsWeekend\").agg(avg(\"DEPARTURE_DELAY\").alias(\"Avg_Delay\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59b4141-6c65-4e68-85bb-f9a018665bbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, concat, lit, lpad, expr, hour, date_trunc\n",
    "\n",
    "df_flights_fixed = df_jfk_no_outliers.withColumn(\n",
    "    \"ScheduledString\", \n",
    "    concat(\n",
    "        col(\"YEAR\"), lit(\"-\"), \n",
    "        lpad(col(\"MONTH\"), 2, '0'), lit(\"-\"), \n",
    "        lpad(col(\"DAY\"), 2, '0'), lit(\" \"), \n",
    "        expr(\"substr(lpad(cast(SCHEDULED_DEPARTURE as string), 4, '0'), 1, 2)\"), lit(\":\"), \n",
    "        expr(\"substr(lpad(cast(SCHEDULED_DEPARTURE as string), 4, '0'), 3, 2)\"), lit(\":00\")\n",
    "    )\n",
    ").withColumn(\"ScheduledTimestamp\", to_timestamp(col(\"ScheduledString\"), \"yyyy-MM-dd HH:mm:ss\"))\\\n",
    " .withColumn(\"Hour\", hour(col(\"ScheduledTimestamp\"))) # Dodajemy godzinę potrzebną do łączenia\n",
    "\n",
    "# Przygotowanie pogody (zaokrąglenie do godziny)\n",
    "df_weather_hourly = df_weather.withColumn(\"WeatherDate\", col(\"DATE\"))\\\n",
    "    .withColumn(\"WeatherHour\", hour(col(\"WeatherDate\")))\\\n",
    "    .withColumn(\"DateOnly\", to_timestamp(date_trunc(\"day\", col(\"WeatherDate\"))))\n",
    "\n",
    "\n",
    "print(\"Łączenie z pogodą...\")\n",
    "df_joined = df_flights_fixed.join(\n",
    "    df_weather_hourly,\n",
    "    (to_timestamp(date_trunc(\"day\", df_flights_fixed.ScheduledTimestamp)) == df_weather_hourly.DateOnly) & \n",
    "    (df_flights_fixed.Hour == df_weather_hourly.WeatherHour),\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "print(\"Statystyki opóźnień w zależności od pogody (JFK):\")\n",
    "display(df_joined.select(\"DEPARTURE_DELAY\", \"HOURLYVISIBILITY\", \"HOURLYWindSpeed\", \"HOURLYPrecip\").summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17368475-fc02-4f58-8ce4-a1c6f8747557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IHJvdW5kLCBhdmcsIGNvbAoKZGZfd2luZF9hbmFseXNpcyA9IGRmX2pvaW5lZC5maWx0ZXIoY29sKCJERVBBUlRVUkVfREVMQVkiKS5pc05vdE51bGwoKSkgXAogICAgLmdyb3VwQnkocm91bmQoY29sKCJIT1VSTFlXaW5kU3BlZWQiKSkuYWxpYXMoIldpbmRTcGVlZCIpKSBcCiAgICAuYWdnKGF2ZygiREVQQVJUVVJFX0RFTEFZIikuYWxpYXMoIkF2Z0RlbGF5IiksIGNvdW50KCIqIikuYWxpYXMoIkZsaWdodENvdW50IikpIFwKICAgIC5vcmRlckJ5KCJXaW5kU3BlZWQiKQoKZGlzcGxheShkZl93aW5kX2FuYWx5c2lzKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksViewf9d895e\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksViewf9d895e\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksViewf9d895e\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksViewf9d895e) SELECT `WindSpeed`,SUM(`AvgDelay`) `column_a1e15dcf283` FROM q GROUP BY `WindSpeed`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksViewf9d895e\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "WindSpeed",
             "id": "column_a1e15dcf281"
            },
            "y": [
             {
              "column": "AvgDelay",
              "id": "column_a1e15dcf283",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_a1e15dcf283": {
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "1b75ff4e-35da-4614-b330-f181cc5c9beb",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "WindSpeed",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "WindSpeed",
           "type": "column"
          },
          {
           "alias": "column_a1e15dcf283",
           "args": [
            {
             "column": "AvgDelay",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import round, avg, col\n",
    "\n",
    "df_wind_analysis = df_joined.filter(col(\"DEPARTURE_DELAY\").isNotNull()) \\\n",
    "    .groupBy(round(col(\"HOURLYWindSpeed\")).alias(\"WindSpeed\")) \\\n",
    "    .agg(avg(\"DEPARTURE_DELAY\").alias(\"AvgDelay\"), count(\"*\").alias(\"FlightCount\")) \\\n",
    "    .orderBy(\"WindSpeed\")\n",
    "\n",
    "display(df_wind_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d761fe-88f7-47ad-a172-a3fee666a199",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IHJvdW5kLCBhdmcsIGNvbAoKZGZfdmlzX2FuYWx5c2lzID0gZGZfam9pbmVkLmZpbHRlcihjb2woIkRFUEFSVFVSRV9ERUxBWSIpLmlzTm90TnVsbCgpKSBcCiAgICAuZ3JvdXBCeShyb3VuZChjb2woIkhPVVJMWVZJU0lCSUxJVFkiKSkuYWxpYXMoIlZpc2liaWxpdHkiKSkgXAogICAgLmFnZyhhdmcoIkRFUEFSVFVSRV9ERUxBWSIpLmFsaWFzKCJBdmdEZWxheSIpLCBjb3VudCgiKiIpLmFsaWFzKCJGbGlnaHRDb3VudCIpKSBcCiAgICAub3JkZXJCeSgiVmlzaWJpbGl0eSIpCgpkaXNwbGF5KGRmX3Zpc19hbmFseXNpcyk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView3a7947c\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView3a7947c\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView3a7947c\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView3a7947c) SELECT `Visibility`,SUM(`AvgDelay`) `column_a1e15dcf308` FROM q GROUP BY `Visibility`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView3a7947c\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "Visibility",
             "id": "column_a1e15dcf306"
            },
            "y": [
             {
              "column": "AvgDelay",
              "id": "column_a1e15dcf308",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_a1e15dcf308": {
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "18d4e282-17f4-4abf-912e-6730ada64196",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 9.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "Visibility",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "Visibility",
           "type": "column"
          },
          {
           "alias": "column_a1e15dcf308",
           "args": [
            {
             "column": "AvgDelay",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import round, avg, col\n",
    "\n",
    "df_vis_analysis = df_joined.filter(col(\"DEPARTURE_DELAY\").isNotNull()) \\\n",
    "    .groupBy(round(col(\"HOURLYVISIBILITY\")).alias(\"Visibility\")) \\\n",
    "    .agg(avg(\"DEPARTURE_DELAY\").alias(\"AvgDelay\"), count(\"*\").alias(\"FlightCount\")) \\\n",
    "    .orderBy(\"Visibility\")\n",
    "\n",
    "display(df_vis_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecc338df-8379-4f10-92b4-89f5af389970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZGZfdGltZV9hbmFseXNpcyA9IGRmX2pvaW5lZC5maWx0ZXIoY29sKCJERVBBUlRVUkVfREVMQVkiKS5pc05vdE51bGwoKSkgXAogICAgLmdyb3VwQnkoIkhvdXIiKSBcCiAgICAuYWdnKGF2ZygiREVQQVJUVVJFX0RFTEFZIikuYWxpYXMoIkF2Z0RlbGF5IikpIFwKICAgIC5vcmRlckJ5KCJIb3VyIikKCmRpc3BsYXkoZGZfdGltZV9hbmFseXNpcyk=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView02a7242\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView02a7242\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView02a7242\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView02a7242) SELECT `Hour`,SUM(`AvgDelay`) `column_a1e15dcf294` FROM q GROUP BY `Hour`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView02a7242\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "Hour",
             "id": "column_a1e15dcf293"
            },
            "y": [
             {
              "column": "AvgDelay",
              "id": "column_a1e15dcf294",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "line",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_a1e15dcf294": {
             "name": "AvgDelay",
             "type": "line",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "92cd593e-e58c-409a-aae1-eabfba3fb55d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 9.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "Hour",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "Hour",
           "type": "column"
          },
          {
           "alias": "column_a1e15dcf294",
           "args": [
            {
             "column": "AvgDelay",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_time_analysis = df_joined.filter(col(\"DEPARTURE_DELAY\").isNotNull()) \\\n",
    "    .groupBy(\"Hour\") \\\n",
    "    .agg(avg(\"DEPARTURE_DELAY\").alias(\"AvgDelay\")) \\\n",
    "    .orderBy(\"Hour\")\n",
    "\n",
    "display(df_time_analysis)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
